{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEMMING \n",
    "\n",
    "The different stemmers used to remove affixes and get the stem of different words are:\n",
    "1. Porter Stemmer\n",
    "2. Lancaster Stemmer\n",
    "3. Snowball Stemmer\n",
    "\n",
    "Some of the rules and conclusions observed are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "ps = PorterStemmer()\n",
    "lc = LancasterStemmer()\n",
    "sb = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['caresses','flies', 'dies', 'ponies', 'denied','Died',\n",
    "         'Dying','dying','Flying','flying',\n",
    "         'disability', 'professionally','mindlessly',\n",
    "         'killing','digging','running',\n",
    "         'having','making','siezing','electricity',\n",
    "         'agreed', 'happiness', 'humbled', 'beautiful', 'careful','owned', 'stating', \n",
    "         'itemization','sensational', 'traditional', \n",
    "         'reference', 'plotted']\n",
    "\n",
    "PSstems = [ps.stem(w) for w in words]\n",
    "LCstems = [lc.stem(w) for w in words]\n",
    "SBstems = [sb.stem(w) for w in words]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Words'] = np.array(words)\n",
    "df['Porter'] = np.array(PSstems)\n",
    "df['Lancaster'] = np.array(LCstems)\n",
    "df['Snowball'] = np.array(SBstems)\n",
    "\n",
    "df1=df.set_index('Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Porter Lancaster    Snowball\n",
      "Words                                           \n",
      "caresses            caress    caress      caress\n",
      "flies                  fli       fli         fli\n",
      "dies                   die       die         die\n",
      "ponies                poni      pony        poni\n",
      "denied                deni      deny        deni\n",
      "Died                   die      died         die\n",
      "Dying                   dy     dying         die\n",
      "dying                  die     dying         die\n",
      "Flying                 fli       fly         fli\n",
      "flying                 fli       fly         fli\n",
      "disability          disabl       dis      disabl\n",
      "professionally  profession   profess  profession\n",
      "mindlessly      mindlessli  mindless    mindless\n",
      "killing               kill       kil        kill\n",
      "digging                dig       dig         dig\n",
      "running                run       run         run\n",
      "having                have       hav        have\n",
      "making                make       mak        make\n",
      "siezing               siez      siez        siez\n",
      "electricity         electr     elect      electr\n",
      "agreed                agre     agree        agre\n",
      "happiness            happi     happy       happi\n",
      "humbled              humbl     humbl       humbl\n",
      "beautiful           beauti    beauty      beauti\n",
      "careful               care       car        care\n",
      "owned                  own       own         own\n",
      "stating              state      stat       state\n",
      "itemization           item      item        item\n",
      "sensational         sensat      sens      sensat\n",
      "traditional         tradit    tradit      tradit\n",
      "reference            refer       ref       refer\n",
      "plotted               plot      plot        plot\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions drawn: \n",
    "\n",
    "1) Here we can see that for words like 'Stating', Lancaster more aggresively stems the word to 'stat' while Porter and Snowball stemmer correctly stems the word to 'state'.Also for the word 'Disablity' Lancaster over stems the word to 'dis'. Similarly for words like 'reference', 'sensational', 'professionally', etc. \n",
    "<br><br> \n",
    "2) The case of the word does make a difference in the case of Porter stemmer. For example it correctly stems Dying --> die but incorrectly stems dying --> dy. While for Lancaster the case of the word doesnt matter. \n",
    "<br><br>\n",
    "3) For words with multiple affixes such as 'Disadvantage', 'mindlessly',etc none of the stemmers are able to find the correct stem and the extend of stemming is different for each stemmer.\n",
    "<br><br>\n",
    "4) Most of the times Porter and Snowball work properly with rules like Consonant doubling (running --> run) and E deletion (Have-->having) while lancaster fails sometimes.\n",
    "<br><br>\n",
    "5) Some of the general rules which I noticed are-<br>\n",
    "SSES->SS (Eg. caresses -> caress)<br>\n",
    "IES->I \t (Eg. ponies -> poni)<br>\n",
    "S->Null<br>\n",
    "ING->Null<br>\n",
    "ED->Null<br>\n",
    "FUL->Null<br>\n",
    "NESS->Null<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
